{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1133655,"sourceType":"datasetVersion","datasetId":633717}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 🚀 ELEVVO Internship Task\n#### 👤 Author: Ali Muhammed\n#### 🧠 Task Level: 3\n#### 🚀 Task Number: 6\n\n## 🎬 Importing the tools and library","metadata":{}},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:15:27.635214Z","iopub.execute_input":"2025-08-25T20:15:27.635497Z","iopub.status.idle":"2025-08-25T20:15:34.293251Z","shell.execute_reply.started":"2025-08-25T20:15:27.635474Z","shell.execute_reply":"2025-08-25T20:15:34.292366Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.5.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.5 fsspec-2025.3.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import transformers\nfrom transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\nfrom datasets import load_dataset\nimport evaluate\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:15:34.294832Z","iopub.execute_input":"2025-08-25T20:15:34.295106Z","iopub.status.idle":"2025-08-25T20:16:13.178642Z","shell.execute_reply.started":"2025-08-25T20:15:34.295078Z","shell.execute_reply":"2025-08-25T20:16:13.177874Z"}},"outputs":[{"name":"stderr","text":"2025-08-25 20:15:52.001350: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756152952.376790      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756152952.479127      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"dataset = load_dataset(\"squad\", split=\"validation[:50]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:16:13.179449Z","iopub.execute_input":"2025-08-25T20:16:13.180177Z","iopub.status.idle":"2025-08-25T20:16:17.221025Z","shell.execute_reply.started":"2025-08-25T20:16:13.180156Z","shell.execute_reply":"2025-08-25T20:16:17.220485Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d6a944222c1403d828ce61664cda4a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83211ebed97f4544a68e507f6303ffdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/validation-00000-of-00001.par(…):   0%|          | 0.00/1.82M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"529d1f379c95486c912942e84bc1c47a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20a89f64019944f483a3671710bd1ea2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec0fc2d8907342b28731da1bba78820a"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"model_name = \"distilbert-base-cased-distilled-squad\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)\n\nqa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:16:17.222383Z","iopub.execute_input":"2025-08-25T20:16:17.222588Z","iopub.status.idle":"2025-08-25T20:16:20.854806Z","shell.execute_reply.started":"2025-08-25T20:16:17.222571Z","shell.execute_reply":"2025-08-25T20:16:20.854016Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c49fca5c30a840408829ea8a54da0fbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7f1ab15bdd841af97733ab86db27622"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf75efc5ea2f4375b0cfa78da6fd750b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60e2256d4bc74666850dcf270061e6fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"545a47fe54f04e7dad395f098764a31f"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"context = \"\"\"The Nile River is one of the longest rivers in the world.\nIt flows through Egypt, Sudan, and Ethiopia. It is the lifeline\nof Sudan's economy, supporting agriculture and industry.\"\"\"\nquestion = \"Which countries does the Indus River flow through?\"\n\nresult = qa_pipeline(question=question, context=context)\nprint(\"Answer:\", result['answer'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:16:20.855562Z","iopub.execute_input":"2025-08-25T20:16:20.855775Z","iopub.status.idle":"2025-08-25T20:16:21.471575Z","shell.execute_reply.started":"2025-08-25T20:16:20.855758Z","shell.execute_reply":"2025-08-25T20:16:21.470771Z"}},"outputs":[{"name":"stdout","text":"Answer: Egypt, Sudan, and Ethiopia\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"metric = evaluate.load(\"squad\")\n\ndef evaluate_model(model_name):\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n    qa = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n\n    preds = []\n    refs = []\n\n    for example in dataset:\n        prediction = qa(question=example[\"question\"], context=example[\"context\"])\n        preds.append({\n            \"id\": example[\"id\"],\n            \"prediction_text\": prediction[\"answer\"]\n        })\n        refs.append({\n            \"id\": example[\"id\"],\n            \"answers\": example[\"answers\"]\n        })\n\n    return metric.compute(predictions=preds, references=refs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:16:21.472395Z","iopub.execute_input":"2025-08-25T20:16:21.472658Z","iopub.status.idle":"2025-08-25T20:16:22.092521Z","shell.execute_reply.started":"2025-08-25T20:16:21.472632Z","shell.execute_reply":"2025-08-25T20:16:22.091969Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64c7a3f7b3194cf8a334536a10cbe915"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac7bb2ae3753427688d8e0a80e5618ab"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"'''print(\"\\n=== Simple QA CLI ===\")\nwhile True:\n    ctx = input(\"\\nEnter context (or type 'exit' to quit): \")\n    if ctx.lower() == \"exit\":\n        break\n    ques = input(\"Enter question: \")\n    answer = qa_pipeline(question=ques, context=ctx)\n    print(\"Answer:\", answer[\"answer\"])'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:16:22.093156Z","iopub.execute_input":"2025-08-25T20:16:22.093332Z","iopub.status.idle":"2025-08-25T20:16:22.097936Z","shell.execute_reply.started":"2025-08-25T20:16:22.093316Z","shell.execute_reply":"2025-08-25T20:16:22.097188Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'print(\"\\n=== Simple QA CLI ===\")\\nwhile True:\\n    ctx = input(\"\\nEnter context (or type \\'exit\\' to quit): \")\\n    if ctx.lower() == \"exit\":\\n        break\\n    ques = input(\"Enter question: \")\\n    answer = qa_pipeline(question=ques, context=ctx)\\n    print(\"Answer:\", answer[\"answer\"])'"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"models_to_test = {\n    \"BERT\": \"bert-large-uncased-whole-word-masking-finetuned-squad\",\n    \"RoBERTa\": \"deepset/roberta-base-squad2\",\n    \"ALBERT\": \"twmkn9/albert-base-v2-squad2\"\n}\n\nresults = {}\nfor name, model_id in models_to_test.items():\n    print(f\"Evaluating {name}...\")\n    results[name] = evaluate_model(model_id)\n\nresults\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:16:22.098724Z","iopub.execute_input":"2025-08-25T20:16:22.098914Z","iopub.status.idle":"2025-08-25T20:16:40.257590Z","shell.execute_reply.started":"2025-08-25T20:16:22.098898Z","shell.execute_reply":"2025-08-25T20:16:40.256857Z"}},"outputs":[{"name":"stdout","text":"Evaluating BERT...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ebee5e99d1a4f63af5c061265437246"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03a8cbebf23a4b9ab489252ca6b41135"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"991b8de64db04b3ea4bfeb54df4fbd1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e882184d1882448b89a5f2e8a9280bd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c11e2f3836642aeb4988e09379e20e5"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nDevice set to use cuda:0\nYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"},{"name":"stdout","text":"Evaluating RoBERTa...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b5439968fc947e5ae9211ca462f6a67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc7477973c2f420baeafce3fe8f95c20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cc3d1dbbc7f4952aa1859049e6254e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d78ebf0887f464d9f2225b42335bd0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3afd97d16768499bbd85638fdc961c9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6120e4f622544d78f97780adbf70aa5"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Evaluating ALBERT...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"032c68981a444f7ba85e3e9426bf3eac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/716 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0ea6474e3cd49c785396e61c77ee6e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77ad4703c5de426285af659c9a79201b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd2a17e82ee240da9f8662206b6741d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/46.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5373bc6781a54955bc7814c8494a6b6d"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at twmkn9/albert-base-v2-squad2 were not used when initializing AlbertForQuestionAnswering: ['albert.pooler.bias', 'albert.pooler.weight']\n- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nDevice set to use cuda:0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/46.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a441b32ac69549498137d036284b6cea"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'BERT': {'exact_match': 88.0, 'f1': 94.99047619047619},\n 'RoBERTa': {'exact_match': 96.0, 'f1': 98.45714285714286},\n 'ALBERT': {'exact_match': 82.0, 'f1': 84.04444444444445}}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame(results).T\ndf\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:16:40.258421Z","iopub.execute_input":"2025-08-25T20:16:40.258668Z","iopub.status.idle":"2025-08-25T20:16:40.289147Z","shell.execute_reply.started":"2025-08-25T20:16:40.258642Z","shell.execute_reply":"2025-08-25T20:16:40.288463Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"         exact_match         f1\nBERT            88.0  94.990476\nRoBERTa         96.0  98.457143\nALBERT          82.0  84.044444","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>exact_match</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>BERT</th>\n      <td>88.0</td>\n      <td>94.990476</td>\n    </tr>\n    <tr>\n      <th>RoBERTa</th>\n      <td>96.0</td>\n      <td>98.457143</td>\n    </tr>\n    <tr>\n      <th>ALBERT</th>\n      <td>82.0</td>\n      <td>84.044444</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"context = \"\"\"The Nile River is one of the longest rivers in the world.\nIt flows through Egypt, Sudan, and Ethiopia. It is the lifeline\nof Sudan's economy, supporting agriculture and industry.\"\"\"\nquestion = \"Which countries does the Indus River flow through?\"\n\n\nmodels = {\n    \"distilbert\": \"distilbert-base-cased-distilled-squad\",\n    \"BERT\": \"bert-large-uncased-whole-word-masking-finetuned-squad\",\n    \"RoBERTa\": \"deepset/roberta-base-squad2\",\n    \"ALBERT\": \"twmkn9/albert-base-v2-squad2\"\n}\n\n#model_in = input(\"which model do you want (distilbert - BERT - RoBERTa - ALBERT) : \")\nmodel_in = 'BERT'\nmodel_name = models.get(model_in)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nqua_pipeline = pipeline(\"question-answering\", model=model_name, tokenizer=tokenizer)\n\n\nresult = qua_pipeline(question=question, context=context)\nprint(\"Answer:\", result['answer'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:16:40.291417Z","iopub.execute_input":"2025-08-25T20:16:40.291835Z","iopub.status.idle":"2025-08-25T20:16:48.580263Z","shell.execute_reply.started":"2025-08-25T20:16:40.291816Z","shell.execute_reply":"2025-08-25T20:16:48.579418Z"}},"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Answer: Egypt, Sudan, and Ethiopia\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"!pip install torch numpy==1.24.3\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\nfrom IPython.display import display, HTML\nimport ipywidgets as widgets\nimport time\n\nMODELS = {\n    \"distilbert\": \"distilbert-base-cased-distilled-squad\",\n    \"BERT\": \"bert-large-uncased-whole-word-masking-finetuned-squad\",\n    \"RoBERTa\": \"deepset/roberta-base-squad2\", \n    \"ALBERT\": \"twmkn9/albert-base-v2-squad2\"\n}\n\nmodels = {}\nloading_status = widgets.Output()\n\nwith loading_status:\n    display(HTML(\"<h3>🔄 Loading models...</h3>\"))\n    \n    for model_name, model_path in MODELS.items():\n        try:\n            display(HTML(f\"<p>Loading {model_name}...</p>\"))\n            models[model_name] = pipeline(\n                'question-answering', \n                model=model_path, \n                tokenizer=model_path\n            )\n            display(HTML(f\"<p style='color:green'>✅ {model_name} loaded successfully!</p>\"))\n        except Exception as e:\n            display(HTML(f\"<p style='color:red'>❌ Error loading {model_name}: {str(e)}</p>\"))\n            models[model_name] = None\n    \n    display(HTML(\"<p style='color:green'><strong>🎉 All models loaded!</strong></p>\"))\n\n# Create widgets\ncontext_text = widgets.Textarea(\n    description=\"📜 Context:\", \n    layout={'width': '100%', 'height': '200px'},\n    placeholder=\"Enter the paragraph or context text here...\"\n)\nquestion_text = widgets.Text(\n    description=\"❓ Question:\", \n    placeholder=\"Enter your question here...\"\n)\n\n# Model selection checkboxes\nmodel_checkboxes = []\nfor model_name in MODELS.keys():\n    checkbox = widgets.Checkbox(\n        value=True,\n        description=model_name,\n        disabled=False\n    )\n    model_checkboxes.append(checkbox)\n\nselect_all_btn = widgets.Button(description=\"Select All Models\", button_style='success')\ndeselect_all_btn = widgets.Button(description=\"Deselect All\", button_style='warning')\n\n# Create a grid for checkboxes\ncheckbox_grid = widgets.GridBox(\n    model_checkboxes,\n    layout=widgets.Layout(\n        width='100%',\n        grid_template_columns='repeat(2, 1fr)',\n        grid_gap='10px'\n    )\n)\n\nsubmit_btn = widgets.Button(\n    description=\"🚀 Get Answers from Selected Models\", \n    button_style='primary',\n    icon='rocket'\n)\nclear_btn = widgets.Button(\n    description=\"🧹 Clear\", \n    button_style='info',\n    icon='eraser'\n)\n\noutput = widgets.Output()\n\n# Button functions\ndef select_all_models(b):\n    for checkbox in model_checkboxes:\n        checkbox.value = True\n\ndef deselect_all_models(b):\n    for checkbox in model_checkboxes:\n        checkbox.value = False\n\ndef clear_fields(b):\n    context_text.value = ''\n    question_text.value = ''\n    with output:\n        output.clear_output()\n\ndef get_answers(b):\n    with output:\n        output.clear_output()\n        context = context_text.value.strip()\n        question = question_text.value.strip()\n        \n        # Get selected models\n        selected_models = []\n        for i, checkbox in enumerate(model_checkboxes):\n            if checkbox.value:\n                model_name = list(MODELS.keys())[i]\n                selected_models.append(model_name)\n        \n        if not context or not question:\n            display(HTML(\"\"\"\n            <div style='background-color:#f8d7da; color:#721c24; padding:15px; \n                         border-radius:8px; border-left:4px solid #dc3545; margin:10px 0;'>\n                <strong>❌ Error:</strong> Please enter both context and question!\n            </div>\n            \"\"\"))\n            return\n            \n        if not selected_models:\n            display(HTML(\"\"\"\n            <div style='background-color:#fff3cd; color:#856404; padding:15px; \n                         border-radius:8px; border-left:4px solid #ffc107; margin:10px 0;'>\n                <strong>⚠️ Warning:</strong> Please select at least one model!\n            </div>\n            \"\"\"))\n            return\n        \n        # Display processing message\n        processing_html = f\"\"\"\n        <div style='background-color:#d1ecf1; color:#0c5460; padding:15px; \n                    border-radius:8px; border-left:4px solid #17a2b8; margin:10px 0;'>\n            <strong>⏳ Processing...</strong> Getting answers from {len(selected_models)} models...\n        </div>\n        \"\"\"\n        processing_msg = display(HTML(processing_html), display_id=True)\n        \n        results = []\n        \n        for model_name in selected_models:\n            if models[model_name] is None:\n                results.append({\n                    'model': model_name,\n                    'error': 'Model failed to load'\n                })\n                continue\n            \n            try:\n                # Get answer using pipeline\n                result = models[model_name]({\n                    'context': context,\n                    'question': question\n                })\n                \n                results.append({\n                    'model': model_name,\n                    'answer': result['answer'],\n                    'confidence': result['score'],\n                    'error': None\n                })\n                \n            except Exception as e:\n                results.append({\n                    'model': model_name,\n                    'error': str(e)\n                })\n        \n        # Clear processing message\n        processing_msg.update(HTML(\"\"))\n        \n        # Display results\n        display(HTML(f\"\"\"\n        <div style='background-color:#d4edda; color:#155724; padding:15px; \n                    border-radius:8px; border-left:4px solid #28a745; margin:10px 0;'>\n            <strong>✅ Analysis Complete!</strong> Processed {len(results)} models.\n        </div>\n        \"\"\"))\n        \n        for result in results:\n            if result['error']:\n                # Display error\n                display(HTML(f\"\"\"\n                <div style='background-color:#f8d7da; color:#721c24; padding:15px; \n                            border-radius:8px; border-left:4px solid #dc3545; margin:10px 0;'>\n                    <div style='display: flex; justify-content: space-between; align-items: center;'>\n                        <strong>🤖 {result['model']}</strong>\n                        <span style='background-color:#dc3545; color:white; padding:3px 10px; \n                                    border-radius:15px; font-size:0.9em;'>Error</span>\n                    </div>\n                    <p style='margin:10px 0 0 0;'><strong>Error:</strong> {result['error']}</p>\n                </div>\n                \"\"\"))\n            else:\n                # Display success result\n                confidence = result['confidence']\n                confidence_percent = f\"{confidence:.2%}\"\n                \n                # Color coding based on confidence\n                if confidence > 0.7:\n                    confidence_color = \"#28a745\"  # Green\n                elif confidence > 0.4:\n                    confidence_color = \"#ffc107\"  # Yellow\n                else:\n                    confidence_color = \"#dc3545\"  # Red\n                \n                display(HTML(f\"\"\"\n                <div style='background-color:#f8f9fa; padding:15px; border-radius:8px; \n                            border-left:4px solid #4361ee; margin:10px 0;'>\n                    <div style='display: flex; justify-content: space-between; align-items: center;'>\n                        <strong style='color:#3a0ca3;'>🤖 {result['model']}</strong>\n                        <span style='background-color:{confidence_color}; color:white; padding:3px 10px; \n                                    border-radius:15px; font-size:0.9em; font-weight:bold;'>\n                            {confidence_percent} confidence\n                        </span>\n                    </div>\n                    <p style='margin:10px 0 0 0; font-size:1.1em;'>\n                        <strong>Answer:</strong> {result['answer']}\n                    </p>\n                </div>\n                \"\"\"))\n\n# Connect buttons to functions\nselect_all_btn.on_click(select_all_models)\ndeselect_all_btn.on_click(deselect_all_models)\nsubmit_btn.on_click(get_answers)\nclear_btn.on_click(clear_fields)\n\n# Create button layout\nbutton_row = widgets.HBox([select_all_btn, deselect_all_btn, clear_btn, submit_btn])\n\n# Display everything\ndisplay(HTML(\"\"\"\n<style>\n    .widget-label { font-weight: bold; color: #3a0ca3; }\n    .widget-button { font-weight: bold; }\n</style>\n\"\"\"))\n\ndisplay(HTML(\"<h1>🧠 Multi-Model Question Answering System</h1>\"))\ndisplay(HTML(\"<h3>Select models and enter context + question to get answers</h3>\"))\n\ndisplay(loading_status)\ndisplay(context_text)\ndisplay(question_text)\n\ndisplay(HTML(\"<h4>🔧 Select Models:</h4>\"))\ndisplay(checkbox_grid)\ndisplay(button_row)\ndisplay(output)\n\n# Add social links at the bottom\ndisplay(HTML(\"\"\"\n<div style='margin-top:30px; padding:20px; background-color:#f8f9fa; border-radius:10px; text-align:center;'>\n    <h4>🔗 Connect with me</h4>\n    <div style='display: flex; justify-content: center; gap: 20px; margin-top: 10px;'>\n        <a href='https://www.linkedin.com/in/ali-muhammed-salah' target='_blank' style='text-decoration: none;'>\n            <span style='background-color:#0077b5; color:white; padding:10px 15px; border-radius:5px;'>\n                📘 LinkedIn\n            </span>\n        </a>\n        <a href='https://www.kaggle.com/alimuhammed10' target='_blank' style='text-decoration: none;'>\n            <span style='background-color:#20beff; color:white; padding:10px 15px; border-radius:5px;'>\n                🏆 Kaggle\n            </span>\n        </a>\n        <a href='https://github.com/ali-muhammed-salah' target='_blank' style='text-decoration: none;'>\n            <span style='background-color:#333; color:white; padding:10px 15px; border-radius:5px;'>\n                💻 GitHub\n            </span>\n        </a>\n    </div>\n</div>\n\"\"\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:16:48.581210Z","iopub.execute_input":"2025-08-25T20:16:48.581472Z","iopub.status.idle":"2025-08-25T20:18:21.633790Z","shell.execute_reply.started":"2025-08-25T20:16:48.581446Z","shell.execute_reply":"2025-08-25T20:18:21.632853Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nCollecting numpy==1.24.3\n  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nDownloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\nwoodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\nbayesian-optimization 3.0.0 requires numpy>=1.25; python_version < \"3.13\", but you have numpy 1.24.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nfeaturetools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.24.3 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\njax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\ntreescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nalbumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\npymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\nblosc2 3.5.0 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\nxarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nalbucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\njaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.24.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    .widget-label { font-weight: bold; color: #3a0ca3; }\n    .widget-button { font-weight: bold; }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<h1>🧠 Multi-Model Question Answering System</h1>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<h3>Select models and enter context + question to get answers</h3>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78bb2480aeda4e11b858c81b41cc3d3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Textarea(value='', description='📜 Context:', layout=Layout(height='200px', width='100%'), placeholder='Enter t…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d7e98c324fd45c88bcb88891f0ea5a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Text(value='', description='❓ Question:', placeholder='Enter your question here...')","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dee1ab3747da4f338afee0bcb543d834"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<h4>🔧 Select Models:</h4>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"GridBox(children=(Checkbox(value=True, description='distilbert'), Checkbox(value=True, description='BERT'), Ch…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aed34df6975a4ee1a865f31af197446a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(Button(button_style='success', description='Select All Models', style=ButtonStyle()), Button(bu…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8257980312b949159b3cff82e533b4c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0aa6759d79d54810a5c57534b60c2fe0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<div style='margin-top:30px; padding:20px; background-color:#f8f9fa; border-radius:10px; text-align:center;'>\n    <h4>🔗 Connect with me</h4>\n    <div style='display: flex; justify-content: center; gap: 20px; margin-top: 10px;'>\n        <a href='https://www.linkedin.com/in/ali-muhammed-salah' target='_blank' style='text-decoration: none;'>\n            <span style='background-color:#0077b5; color:white; padding:10px 15px; border-radius:5px;'>\n                📘 LinkedIn\n            </span>\n        </a>\n        <a href='https://www.kaggle.com/alimuhammed10' target='_blank' style='text-decoration: none;'>\n            <span style='background-color:#20beff; color:white; padding:10px 15px; border-radius:5px;'>\n                🏆 Kaggle\n            </span>\n        </a>\n        <a href='https://github.com/ali-muhammed-salah' target='_blank' style='text-decoration: none;'>\n            <span style='background-color:#333; color:white; padding:10px 15px; border-radius:5px;'>\n                💻 GitHub\n            </span>\n        </a>\n    </div>\n</div>\n"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"## 👤 Accounts\n### [Linkedin](https://www.linkedin.com/in/ali-muhammed-salah/) [Kaggle](https://www.kaggle.com/alimuhammed10) [GitHub](https://github.com/ali-muhammed-salah)","metadata":{}}]}